{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.6.0'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf \n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt \n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filePath</th>\n",
       "      <th>emotion</th>\n",
       "      <th>isFemale</th>\n",
       "      <th>actorId</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>data/RAVDESS/Audio_Speech_Actors_01-24/Actor_1...</td>\n",
       "      <td>5</td>\n",
       "      <td>True</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>data/RAVDESS/Audio_Speech_Actors_01-24/Actor_1...</td>\n",
       "      <td>6</td>\n",
       "      <td>True</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>data/RAVDESS/Audio_Speech_Actors_01-24/Actor_1...</td>\n",
       "      <td>6</td>\n",
       "      <td>True</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>data/RAVDESS/Audio_Speech_Actors_01-24/Actor_1...</td>\n",
       "      <td>5</td>\n",
       "      <td>True</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>data/RAVDESS/Audio_Speech_Actors_01-24/Actor_1...</td>\n",
       "      <td>7</td>\n",
       "      <td>True</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            filePath  emotion  isFemale  \\\n",
       "0  data/RAVDESS/Audio_Speech_Actors_01-24/Actor_1...        5      True   \n",
       "1  data/RAVDESS/Audio_Speech_Actors_01-24/Actor_1...        6      True   \n",
       "2  data/RAVDESS/Audio_Speech_Actors_01-24/Actor_1...        6      True   \n",
       "3  data/RAVDESS/Audio_Speech_Actors_01-24/Actor_1...        5      True   \n",
       "4  data/RAVDESS/Audio_Speech_Actors_01-24/Actor_1...        7      True   \n",
       "\n",
       "   actorId  \n",
       "0       16  \n",
       "1       16  \n",
       "2       16  \n",
       "3       16  \n",
       "4       16  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampling_rate = '22050'\n",
    "with open('mfcc_trimmed_'+ sampling_rate + '.npy', 'rb') as f:\n",
    "    mfcc_trimmed = np.load(f, allow_pickle=True)\n",
    "    \n",
    "df_raw = pd.read_csv('RAVDESS_speech.csv')\n",
    "df_raw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filePath</th>\n",
       "      <th>emotion</th>\n",
       "      <th>isFemale</th>\n",
       "      <th>actorId</th>\n",
       "      <th>mfcc_trimmed_22050</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>data/RAVDESS/Audio_Speech_Actors_01-24/Actor_1...</td>\n",
       "      <td>5</td>\n",
       "      <td>True</td>\n",
       "      <td>16</td>\n",
       "      <td>[[-723.22266, -714.97565, -713.3226, -714.5724...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>data/RAVDESS/Audio_Speech_Actors_01-24/Actor_1...</td>\n",
       "      <td>6</td>\n",
       "      <td>True</td>\n",
       "      <td>16</td>\n",
       "      <td>[[-557.34534, -384.11807, -321.34244, -315.224...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>data/RAVDESS/Audio_Speech_Actors_01-24/Actor_1...</td>\n",
       "      <td>6</td>\n",
       "      <td>True</td>\n",
       "      <td>16</td>\n",
       "      <td>[[-538.961, -534.93274, -530.0017, -530.9788, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>data/RAVDESS/Audio_Speech_Actors_01-24/Actor_1...</td>\n",
       "      <td>5</td>\n",
       "      <td>True</td>\n",
       "      <td>16</td>\n",
       "      <td>[[-590.68286, -587.66205, -585.7887, -588.7289...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>data/RAVDESS/Audio_Speech_Actors_01-24/Actor_1...</td>\n",
       "      <td>7</td>\n",
       "      <td>True</td>\n",
       "      <td>16</td>\n",
       "      <td>[[-826.90735, -811.848, -799.259, -821.14, -72...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            filePath  emotion  isFemale  \\\n",
       "0  data/RAVDESS/Audio_Speech_Actors_01-24/Actor_1...        5      True   \n",
       "1  data/RAVDESS/Audio_Speech_Actors_01-24/Actor_1...        6      True   \n",
       "2  data/RAVDESS/Audio_Speech_Actors_01-24/Actor_1...        6      True   \n",
       "3  data/RAVDESS/Audio_Speech_Actors_01-24/Actor_1...        5      True   \n",
       "4  data/RAVDESS/Audio_Speech_Actors_01-24/Actor_1...        7      True   \n",
       "\n",
       "   actorId                                 mfcc_trimmed_22050  \n",
       "0       16  [[-723.22266, -714.97565, -713.3226, -714.5724...  \n",
       "1       16  [[-557.34534, -384.11807, -321.34244, -315.224...  \n",
       "2       16  [[-538.961, -534.93274, -530.0017, -530.9788, ...  \n",
       "3       16  [[-590.68286, -587.66205, -585.7887, -588.7289...  \n",
       "4       16  [[-826.90735, -811.848, -799.259, -821.14, -72...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df_raw\n",
    "df['mfcc_trimmed_'+ sampling_rate] = mfcc_trimmed\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['mfcc_shape_of_t'] = [ np.shape(x)[1] for x in df.mfcc_trimmed_22050]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filePath</th>\n",
       "      <th>emotion</th>\n",
       "      <th>isFemale</th>\n",
       "      <th>actorId</th>\n",
       "      <th>mfcc_trimmed_22050</th>\n",
       "      <th>mfcc_shape_of_t</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>data/RAVDESS/Audio_Speech_Actors_01-24/Actor_1...</td>\n",
       "      <td>5</td>\n",
       "      <td>True</td>\n",
       "      <td>16</td>\n",
       "      <td>[[-723.22266, -714.97565, -713.3226, -714.5724...</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>data/RAVDESS/Audio_Speech_Actors_01-24/Actor_1...</td>\n",
       "      <td>6</td>\n",
       "      <td>True</td>\n",
       "      <td>16</td>\n",
       "      <td>[[-557.34534, -384.11807, -321.34244, -315.224...</td>\n",
       "      <td>95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>data/RAVDESS/Audio_Speech_Actors_01-24/Actor_1...</td>\n",
       "      <td>6</td>\n",
       "      <td>True</td>\n",
       "      <td>16</td>\n",
       "      <td>[[-538.961, -534.93274, -530.0017, -530.9788, ...</td>\n",
       "      <td>130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>data/RAVDESS/Audio_Speech_Actors_01-24/Actor_1...</td>\n",
       "      <td>5</td>\n",
       "      <td>True</td>\n",
       "      <td>16</td>\n",
       "      <td>[[-590.68286, -587.66205, -585.7887, -588.7289...</td>\n",
       "      <td>102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>data/RAVDESS/Audio_Speech_Actors_01-24/Actor_1...</td>\n",
       "      <td>7</td>\n",
       "      <td>True</td>\n",
       "      <td>16</td>\n",
       "      <td>[[-826.90735, -811.848, -799.259, -821.14, -72...</td>\n",
       "      <td>108</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            filePath  emotion  isFemale  \\\n",
       "0  data/RAVDESS/Audio_Speech_Actors_01-24/Actor_1...        5      True   \n",
       "1  data/RAVDESS/Audio_Speech_Actors_01-24/Actor_1...        6      True   \n",
       "2  data/RAVDESS/Audio_Speech_Actors_01-24/Actor_1...        6      True   \n",
       "3  data/RAVDESS/Audio_Speech_Actors_01-24/Actor_1...        5      True   \n",
       "4  data/RAVDESS/Audio_Speech_Actors_01-24/Actor_1...        7      True   \n",
       "\n",
       "   actorId                                 mfcc_trimmed_22050  mfcc_shape_of_t  \n",
       "0       16  [[-723.22266, -714.97565, -713.3226, -714.5724...               99  \n",
       "1       16  [[-557.34534, -384.11807, -321.34244, -315.224...               95  \n",
       "2       16  [[-538.961, -534.93274, -530.0017, -530.9788, ...              130  \n",
       "3       16  [[-590.68286, -587.66205, -585.7887, -588.7289...              102  \n",
       "4       16  [[-826.90735, -811.848, -799.259, -821.14, -72...              108  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "150    32\n",
       "149    31\n",
       "156    30\n",
       "153    28\n",
       "154    28\n",
       "       ..\n",
       "178     1\n",
       "217     1\n",
       "70      1\n",
       "68      1\n",
       "216     1\n",
       "Name: mfcc_shape_of_t, Length: 139, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['mfcc_shape_of_t'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.bar(df['mfcc_shape_of_t'].value_counts().index, \\\n",
    "       df['mfcc_shape_of_t'].value_counts().values, \\\n",
    "           width=1, edgecolor=\"white\", linewidth=0.7)\n",
    "\n",
    "plt.title('distrubution of duration of each sample')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['mfcc_t'] = [  x.T for x in df.mfcc_trimmed_22050]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras\n",
    "mfcc_pad = tf.keras.preprocessing.sequence.pad_sequences(df.mfcc_t, padding=\"post\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1440, 217, 13)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mfcc_pad.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_ds = tf.data.Dataset.from_tensor_slices((mfcc_pad, df.emotion))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "Error",
     "evalue": "Session cannot generate requests",
     "output_type": "error",
     "traceback": [
      "Error: Session cannot generate requests",
      "at S.executeCodeCell (c:\\Users\\Shadow\\.vscode\\extensions\\ms-toolsai.jupyter-2021.10.1101450599\\out\\client\\extension.js:66:301742)",
      "at S.execute (c:\\Users\\Shadow\\.vscode\\extensions\\ms-toolsai.jupyter-2021.10.1101450599\\out\\client\\extension.js:66:300732)",
      "at S.start (c:\\Users\\Shadow\\.vscode\\extensions\\ms-toolsai.jupyter-2021.10.1101450599\\out\\client\\extension.js:66:296408)",
      "at processTicksAndRejections (internal/process/task_queues.js:93:5)",
      "at async t.CellExecutionQueue.executeQueuedCells (c:\\Users\\Shadow\\.vscode\\extensions\\ms-toolsai.jupyter-2021.10.1101450599\\out\\client\\extension.js:66:312326)",
      "at async t.CellExecutionQueue.start (c:\\Users\\Shadow\\.vscode\\extensions\\ms-toolsai.jupyter-2021.10.1101450599\\out\\client\\extension.js:66:311862)"
     ]
    }
   ],
   "source": [
    "print('x')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "Error",
     "evalue": "Session cannot generate requests",
     "output_type": "error",
     "traceback": [
      "Error: Session cannot generate requests",
      "at S.executeCodeCell (c:\\Users\\Shadow\\.vscode\\extensions\\ms-toolsai.jupyter-2021.10.1101450599\\out\\client\\extension.js:66:301742)",
      "at S.execute (c:\\Users\\Shadow\\.vscode\\extensions\\ms-toolsai.jupyter-2021.10.1101450599\\out\\client\\extension.js:66:300732)",
      "at S.start (c:\\Users\\Shadow\\.vscode\\extensions\\ms-toolsai.jupyter-2021.10.1101450599\\out\\client\\extension.js:66:296408)",
      "at processTicksAndRejections (internal/process/task_queues.js:93:5)",
      "at async t.CellExecutionQueue.executeQueuedCells (c:\\Users\\Shadow\\.vscode\\extensions\\ms-toolsai.jupyter-2021.10.1101450599\\out\\client\\extension.js:66:312326)",
      "at async t.CellExecutionQueue.start (c:\\Users\\Shadow\\.vscode\\extensions\\ms-toolsai.jupyter-2021.10.1101450599\\out\\client\\extension.js:66:311862)"
     ]
    }
   ],
   "source": [
    "TAKE_SIZE = int(0.8*df.shape[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "Error",
     "evalue": "Session cannot generate requests",
     "output_type": "error",
     "traceback": [
      "Error: Session cannot generate requests",
      "at S.executeCodeCell (c:\\Users\\Shadow\\.vscode\\extensions\\ms-toolsai.jupyter-2021.10.1101450599\\out\\client\\extension.js:66:301742)",
      "at S.execute (c:\\Users\\Shadow\\.vscode\\extensions\\ms-toolsai.jupyter-2021.10.1101450599\\out\\client\\extension.js:66:300732)",
      "at S.start (c:\\Users\\Shadow\\.vscode\\extensions\\ms-toolsai.jupyter-2021.10.1101450599\\out\\client\\extension.js:66:296408)",
      "at runMicrotasks (<anonymous>)",
      "at processTicksAndRejections (internal/process/task_queues.js:93:5)",
      "at async t.CellExecutionQueue.executeQueuedCells (c:\\Users\\Shadow\\.vscode\\extensions\\ms-toolsai.jupyter-2021.10.1101450599\\out\\client\\extension.js:66:312326)",
      "at async t.CellExecutionQueue.start (c:\\Users\\Shadow\\.vscode\\extensions\\ms-toolsai.jupyter-2021.10.1101450599\\out\\client\\extension.js:66:311862)"
     ]
    }
   ],
   "source": [
    "# Train Test Split\n",
    "\n",
    "train_data = full_ds.take(TAKE_SIZE).shuffle(TAKE_SIZE)\n",
    "train_data = train_data.batch(64)\n",
    "\n",
    "test_data = full_ds.skip(TAKE_SIZE)\n",
    "test_data = test_data.batch(64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Conv2D, MaxPool2D, Flatten, Dense\n",
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "\n",
    "model = Sequential()model.add(layers.Conv1D(256, 5,padding='same',\n",
    "                 input_shape=(236,40)))\n",
    "model.add(layers.Activation('relu'))\n",
    "model.add(layers.MaxPooling1D(pool_size=(8)))\n",
    "model.add(layers.Dropout(0.2))model.add(layers.Conv1D(128, 5,padding='same'))\n",
    "model.add(layers.Activation('relu'))\n",
    "model.add(layers.MaxPooling1D(pool_size=(4)))\n",
    "model.add(layers.Dropout(0.1))model.add(layers.Flatten())\n",
    "model.add(layers.Dense(64))\n",
    "model.add(layers.Dense(7))\n",
    "model.add(layers.Activation('softmax'))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b3ba2566441a7c06988d0923437866b63cedc61552a5af99d1f4fb67d367b25f"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
